{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOeI-etTR9KM",
    "outputId": "be4cbc3f-e5dc-40d8-e541-3fc2310c793f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VPygOB-qqEf",
    "outputId": "4253a24a-8d13-4cf1-d914-b18fa4f5f0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/group-1.3\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/group-1.3/\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwu_e0f-iNw6"
   },
   "outputs": [],
   "source": [
    "!pip install mittens transformers\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkZo22Z4Kc1j"
   },
   "source": [
    "# student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lHqrAbCiF47",
    "outputId": "04326bc2-3132-4113-e206-a6c6b76d6f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/group-1.3/LeverageJustAFewKeywords\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/group-1.3/LeverageJustAFewKeywords/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwTgnv29PMAk"
   },
   "source": [
    "## Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8NrM5x8OhLA"
   },
   "outputs": [],
   "source": [
    "from train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izXAweH1Kce0"
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'domain': 'organic',\n",
    "    'experiment_mode': 'one-time', # 'multi-times', 'debug'\n",
    "    'lr': 5e-4,\n",
    "    'batch_size': 1024,\n",
    "    'inner_iter': 5,\n",
    "    'epochs': 6,\n",
    "    'gpu': '1',\n",
    "    'student': {\n",
    "        'pretrained': 'word2vec',\n",
    "        'wv_path': '../wv/w2v_corpus_wotf1_tuned.bin',\n",
    "        'wv_mode': 'tuned',     # 'pretrained'\n",
    "        'pretrained_dim': 300,\n",
    "        'num_aspect': 6,\n",
    "        'freeze_emb': 1,\n",
    "        'dropout': 0.5,\n",
    "        'weight_decay': 0.1,\n",
    "    },\n",
    "    'data_dir': '../processed/',\n",
    "    'output_dir': '../experiments/',\n",
    "    'general_asp': 0,\n",
    "    'maxlen': 40\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G675x5TWOpcb",
    "outputId": "179e87e6-0886-41d7-c64b-b2d1377f478f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25840, 300) matrix from ../wv/w2v_corpus_wotf1_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_tuned.bin\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(hparams, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRdLeZ9QihA_"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR-D22iCPNd8"
   },
   "source": [
    "## parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEEUacRdEEwt"
   },
   "outputs": [],
   "source": [
    "! python parser.py --domain bags_and_cases --experiment_mode one-time --lr 5e-4 --batch_size 512 --pretrained word2vec --wv_path ../wv/w2v_oposum --wv_mode tuned \\\n",
    "            --num_aspects 9 --data_dir ../processed/ --output_dir ../experiments/ --general_asp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIiz6xXXjyaL",
    "outputId": "529fe4e6-a230-4b99-e48c-2ea5ce24cf99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-21 15:02:38.947857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Now GPU: Tesla P100-PCIE-16GB\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.796: 100% 856/856 [00:45<00:00, 18.99it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.590: 100% 856/856 [00:46<00:00, 18.41it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.570: 100% 856/856 [00:47<00:00, 18.21it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.560: 100% 856/856 [00:46<00:00, 18.42it/s]\n",
      "INFO:root:inner epoch: 4\n",
      "avg loss: 1.553: 100% 856/856 [00:46<00:00, 18.49it/s]\n",
      "[1.7956031168175635, 1.589800244284289, 1.5703749654936456, 1.5599102654328971, 1.552581135670994]\n",
      "100% 856/856 [00:46<00:00, 18.41it/s]\n",
      "67.59% (68.93% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.41924471943673997\tmicro f1 score from student: 0.32771495626200126\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.505: 100% 856/856 [00:46<00:00, 18.34it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.499: 100% 856/856 [00:47<00:00, 18.14it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.497: 100% 856/856 [00:47<00:00, 18.07it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.497: 100% 856/856 [00:46<00:00, 18.40it/s]\n",
      "[1.5054828211247364, 1.4987908012329418, 1.497285499716195, 1.497191842436512]\n",
      "100% 856/856 [00:45<00:00, 18.80it/s]\n",
      "73.89% (81.59% after updating z) of samples have same result from student and teacher.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "testing result: micro f1 score from teacher: 0.3748666524429272\tmicro f1 score from student: 0.33838276082782165\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.464: 100% 856/856 [00:46<00:00, 18.27it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.463: 100% 856/856 [00:47<00:00, 17.85it/s]\n",
      "[1.4635326801059403, 1.4627067550111597]\n",
      "100% 856/856 [00:45<00:00, 18.91it/s]\n",
      "81.86% (85.21% after updating z) of samples have same result from student and teacher.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "testing result: micro f1 score from teacher: 0.3695327501600171\tmicro f1 score from student: 0.3304885854491146\n",
      "INFO:root:epoch 0:\tloss: 1.614\tscore: 0.328\tagreement_ratio: 0.676\n",
      "INFO:root:epoch 1:\tloss: 1.500\tscore: 0.338\tagreement_ratio: 0.739\n",
      "INFO:root:epoch 2:\tloss: 1.463\tscore: 0.330\tagreement_ratio: 0.819\n"
     ]
    }
   ],
   "source": [
    "! python parser.py --domain organic --experiment_mode one-time --lr 5e-4 --batch_size 512 --pretrained word2vec --wv_path ../wv/w2v_corpus_wotf1_wostw_tuned.bin --wv_mode tuned \\\n",
    "            --num_aspects 6 --data_dir ../processed/ --output_dir ../experiments/ --general_asp 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSZu_OrfSYhj",
    "outputId": "3223ebcc-36d7-489e-feb3-3dc13722d0a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-25 11:06:38.163147: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Now GPU: Tesla P100-PCIE-16GB\n",
      "experiments setting: {'domain': 'organic', 'experiment_mode': 'multi-times', 'lr': 0.005, 'batch_size': 512, 'inner_iter': 5, 'epochs': 6, 'gpu': '1', 'student': {'pretrained': 'word2vec', 'wv_path': '../wv/w2v_corpus_wotf1_wostw_tuned.bin', 'wv_mode': 'tuned', 'pretrained_dim': 300, 'num_aspect': 6, 'freeze_emb': 1, 'dropout': 0.4, 'weight_decay': 0.01}, 'data_dir': '../processed/', 'output_dir': '../experiments/', 'general_asp': 0, 'maxlen': 40}\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.255: 100% 856/856 [00:46<00:00, 18.45it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.222: 100% 856/856 [00:46<00:00, 18.26it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.220: 100% 856/856 [00:46<00:00, 18.35it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.219: 100% 856/856 [00:48<00:00, 17.63it/s]\n",
      "[1.2549798942963097, 1.2218851469909755, 1.2197938743613173, 1.2191849123408025]\n",
      "100% 856/856 [00:43<00:00, 19.50it/s]\n",
      "64.80% (66.81% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4420738212075955\tmicro f1 score from student: 0.3400896095583529\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.187: 100% 856/856 [00:47<00:00, 18.20it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.185: 100% 856/856 [00:47<00:00, 18.13it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.185: 100% 856/856 [00:46<00:00, 18.34it/s]\n",
      "[1.1873129277759902, 1.1850707037983654, 1.1854753604541732]\n",
      "100% 856/856 [00:44<00:00, 19.13it/s]\n",
      "71.74% (73.62% after updating z) of samples have same result from student and teacher.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "testing result: micro f1 score from teacher: 0.4171111585235758\tmicro f1 score from student: 0.36291871132920844\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.164: 100% 856/856 [00:48<00:00, 17.78it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.163: 100% 856/856 [00:46<00:00, 18.37it/s]\n",
      "[1.1637538974216888, 1.163362322087948]\n",
      "100% 856/856 [00:46<00:00, 18.26it/s]\n",
      "74.74% (77.43% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4045231491359078\tmicro f1 score from student: 0.34969063366759123\n",
      "INFO:root:ISWD iteration: 3\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.148: 100% 856/856 [00:46<00:00, 18.34it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.148: 100% 856/856 [00:46<00:00, 18.57it/s]\n",
      "[1.1480748330147188, 1.1476389520201031]\n",
      "100% 856/856 [00:45<00:00, 18.89it/s]\n",
      "79.02% (80.77% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.37934713036057177\tmicro f1 score from student: 0.3371026242799232\n",
      "INFO:root:ISWD iteration: 4\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.134: 100% 856/856 [00:47<00:00, 17.93it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.133: 100% 856/856 [00:47<00:00, 18.13it/s]\n",
      "[1.1335612793374703, 1.133052343293746]\n",
      "100% 856/856 [00:47<00:00, 18.12it/s]\n",
      "80.54% (80.83% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3787070620866226\tmicro f1 score from student: 0.3313420098143802\n",
      "INFO:root:ISWD iteration: 5\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.128: 100% 856/856 [00:46<00:00, 18.42it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.127: 100% 856/856 [00:46<00:00, 18.43it/s]\n",
      "[1.127757496714035, 1.127342375326101]\n",
      "100% 856/856 [00:46<00:00, 18.27it/s]\n",
      "80.94% (81.69% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3838276082782163\tmicro f1 score from student: 0.3309152976317474\n",
      "INFO:root:epoch 0:\tloss: 1.229\tscore: 0.340\tagreement_ratio: 0.648\n",
      "INFO:root:epoch 1:\tloss: 1.186\tscore: 0.363\tagreement_ratio: 0.717\n",
      "INFO:root:epoch 2:\tloss: 1.164\tscore: 0.350\tagreement_ratio: 0.747\n",
      "INFO:root:epoch 3:\tloss: 1.148\tscore: 0.337\tagreement_ratio: 0.790\n",
      "INFO:root:epoch 4:\tloss: 1.133\tscore: 0.331\tagreement_ratio: 0.805\n",
      "INFO:root:epoch 5:\tloss: 1.128\tscore: 0.331\tagreement_ratio: 0.809\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.262: 100% 856/856 [00:47<00:00, 18.04it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.222: 100% 856/856 [00:47<00:00, 18.11it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.220: 100% 856/856 [00:49<00:00, 17.46it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.220: 100% 856/856 [00:47<00:00, 18.12it/s]\n",
      "[1.2619846599507276, 1.2221124272828348, 1.2195348737360996, 1.2195717021300692]\n",
      "100% 856/856 [00:47<00:00, 18.20it/s]\n",
      "64.64% (66.62% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4467676552165564\tmicro f1 score from student: 0.3430765948367826\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.189: 100% 856/856 [00:48<00:00, 17.78it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.186: 100% 856/856 [00:46<00:00, 18.49it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.186: 100% 856/856 [00:47<00:00, 18.13it/s]\n",
      "[1.1887790127787914, 1.1864303440969681, 1.1862090785038946]\n",
      "100% 856/856 [00:46<00:00, 18.25it/s]\n",
      "71.44% (73.34% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4186046511627907\tmicro f1 score from student: 0.36462556005973973\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.166: 100% 856/856 [00:47<00:00, 18.01it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.165: 100% 856/856 [00:48<00:00, 17.70it/s]\n",
      "[1.1657230431892882, 1.164893205738931]\n",
      "100% 856/856 [00:46<00:00, 18.58it/s]\n",
      "74.40% (77.11% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4068700661403883\tmicro f1 score from student: 0.3560913164070834\n",
      "INFO:root:ISWD iteration: 3\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.150: 100% 856/856 [00:47<00:00, 18.18it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.149: 100% 856/856 [00:48<00:00, 17.76it/s]\n",
      "[1.149851322034809, 1.1490606105251011]\n",
      "100% 856/856 [00:45<00:00, 18.71it/s]\n",
      "78.78% (80.65% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3819074034563687\tmicro f1 score from student: 0.33667591209729036\n",
      "INFO:root:ISWD iteration: 4\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.136: 100% 856/856 [00:46<00:00, 18.57it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.135: 100% 856/856 [00:49<00:00, 17.42it/s]\n",
      "[1.1357236323164446, 1.1350295319282842]\n",
      "100% 856/856 [00:45<00:00, 18.68it/s]\n",
      "80.88% (81.55% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3763601450821421\tmicro f1 score from student: 0.33304885854491145\n",
      "INFO:root:ISWD iteration: 5\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.128: 100% 856/856 [00:48<00:00, 17.54it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.128: 100% 856/856 [00:48<00:00, 17.81it/s]\n",
      "[1.1284649135614528, 1.1281994791509948]\n",
      "100% 856/856 [00:47<00:00, 18.18it/s]\n",
      "81.58% (82.37% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.38276082782163423\tmicro f1 score from student: 0.3313420098143802\n",
      "INFO:root:epoch 0:\tloss: 1.231\tscore: 0.343\tagreement_ratio: 0.646\n",
      "INFO:root:epoch 1:\tloss: 1.187\tscore: 0.365\tagreement_ratio: 0.714\n",
      "INFO:root:epoch 2:\tloss: 1.165\tscore: 0.356\tagreement_ratio: 0.744\n",
      "INFO:root:epoch 3:\tloss: 1.149\tscore: 0.337\tagreement_ratio: 0.788\n",
      "INFO:root:epoch 4:\tloss: 1.135\tscore: 0.333\tagreement_ratio: 0.809\n",
      "INFO:root:epoch 5:\tloss: 1.128\tscore: 0.331\tagreement_ratio: 0.816\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.259: 100% 856/856 [00:48<00:00, 17.76it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.222: 100% 856/856 [00:48<00:00, 17.82it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.221: 100% 856/856 [00:48<00:00, 17.78it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.220: 100% 856/856 [00:48<00:00, 17.67it/s]\n",
      "[1.258750908807895, 1.2224416270782457, 1.2205577717623979, 1.219676204791693]\n",
      "100% 856/856 [00:45<00:00, 18.71it/s]\n",
      "64.27% (66.30% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.44783443567313846\tmicro f1 score from student: 0.3371026242799232\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.190: 100% 856/856 [00:47<00:00, 18.08it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.188: 100% 856/856 [00:47<00:00, 18.15it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.188: 100% 856/856 [00:47<00:00, 18.02it/s]\n",
      "[1.1900174900123448, 1.1879296083455888, 1.1875703335069467]\n",
      "100% 856/856 [00:44<00:00, 19.10it/s]\n",
      "70.83% (72.84% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.41839129507147427\tmicro f1 score from student: 0.3654789844250053\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.168: 100% 856/856 [00:49<00:00, 17.14it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.167: 100% 856/856 [00:47<00:00, 17.95it/s]\n",
      "[1.1677962315451598, 1.167094093912812]\n",
      "100% 856/856 [00:46<00:00, 18.46it/s]\n",
      "74.00% (76.42% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.41284403669724773\tmicro f1 score from student: 0.3545978237678686\n",
      "INFO:root:ISWD iteration: 3\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.152: 100% 856/856 [00:47<00:00, 17.98it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.153: 100% 856/856 [00:47<00:00, 18.04it/s]\n",
      "[1.1524515601275402, 1.1525038488244064]\n",
      "100% 856/856 [00:45<00:00, 18.85it/s]\n",
      "78.70% (80.29% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3838276082782163\tmicro f1 score from student: 0.3411563900149349\n",
      "INFO:root:ISWD iteration: 4\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.138: 100% 856/856 [00:47<00:00, 18.01it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.138: 100% 856/856 [00:48<00:00, 17.80it/s]\n",
      "[1.138036561503171, 1.1378443572043537]\n",
      "100% 856/856 [00:46<00:00, 18.30it/s]\n",
      "80.67% (83.10% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.37593343289950926\tmicro f1 score from student: 0.33347557072754425\n",
      "INFO:root:ISWD iteration: 5\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.130: 100% 856/856 [00:47<00:00, 17.91it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.129: 100% 856/856 [00:46<00:00, 18.34it/s]\n",
      "[1.1295341013922033, 1.1291771576365577]\n",
      "100% 856/856 [00:46<00:00, 18.56it/s]\n",
      "83.04% (84.27% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3823341156390015\tmicro f1 score from student: 0.3313420098143802\n",
      "INFO:root:epoch 0:\tloss: 1.230\tscore: 0.337\tagreement_ratio: 0.643\n",
      "INFO:root:epoch 1:\tloss: 1.189\tscore: 0.365\tagreement_ratio: 0.708\n",
      "INFO:root:epoch 2:\tloss: 1.167\tscore: 0.355\tagreement_ratio: 0.740\n",
      "INFO:root:epoch 3:\tloss: 1.152\tscore: 0.341\tagreement_ratio: 0.787\n",
      "INFO:root:epoch 4:\tloss: 1.138\tscore: 0.333\tagreement_ratio: 0.807\n",
      "INFO:root:epoch 5:\tloss: 1.129\tscore: 0.331\tagreement_ratio: 0.830\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.269: 100% 856/856 [00:48<00:00, 17.64it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.223: 100% 856/856 [00:47<00:00, 18.11it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.220: 100% 856/856 [00:47<00:00, 17.99it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.220: 100% 856/856 [00:47<00:00, 17.99it/s]\n",
      "[1.2689794656759668, 1.2228498553648313, 1.2202257844053697, 1.2196398600413698]\n",
      "100% 856/856 [00:44<00:00, 19.13it/s]\n",
      "64.10% (65.52% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4634094303392362\tmicro f1 score from student: 0.35353104331128654\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.191: 100% 856/856 [00:47<00:00, 17.85it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.188: 100% 856/856 [00:47<00:00, 18.08it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.188: 100% 856/856 [00:45<00:00, 18.63it/s]\n",
      "[1.1908109719542979, 1.1883485616123843, 1.1882838369564754]\n",
      "100% 856/856 [00:47<00:00, 17.88it/s]\n",
      "72.01% (73.38% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4486878600384041\tmicro f1 score from student: 0.39044164710902496\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.164: 100% 856/856 [00:46<00:00, 18.30it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.163: 100% 856/856 [00:47<00:00, 17.88it/s]\n",
      "[1.1638603212712246, 1.1633614637479883]\n",
      "100% 856/856 [00:45<00:00, 18.66it/s]\n",
      "74.85% (77.64% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4096436953275016\tmicro f1 score from student: 0.36761254533816934\n",
      "INFO:root:ISWD iteration: 3\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.145: 100% 856/856 [00:46<00:00, 18.34it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.144: 100% 856/856 [00:46<00:00, 18.29it/s]\n",
      "[1.1445040537270708, 1.1438442763184833]\n",
      "100% 856/856 [00:47<00:00, 18.21it/s]\n",
      "78.09% (80.78% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.38361425218689993\tmicro f1 score from student: 0.34222317047151696\n",
      "INFO:root:ISWD iteration: 4\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.132: 100% 856/856 [00:47<00:00, 18.07it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.132: 100% 856/856 [00:47<00:00, 18.10it/s]\n",
      "[1.1320078513785221, 1.131734090126076]\n",
      "100% 856/856 [00:45<00:00, 18.71it/s]\n",
      "80.77% (81.83% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3853211009174312\tmicro f1 score from student: 0.3341156390014935\n",
      "INFO:root:ISWD iteration: 5\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.128: 100% 856/856 [00:46<00:00, 18.39it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.128: 100% 856/856 [00:47<00:00, 17.97it/s]\n",
      "[1.1281955792420657, 1.1280858465165735]\n",
      "100% 856/856 [00:46<00:00, 18.22it/s]\n",
      "81.86% (83.46% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.38446767655216557\tmicro f1 score from student: 0.331768721997013\n",
      "INFO:root:epoch 0:\tloss: 1.233\tscore: 0.354\tagreement_ratio: 0.641\n",
      "INFO:root:epoch 1:\tloss: 1.189\tscore: 0.390\tagreement_ratio: 0.720\n",
      "INFO:root:epoch 2:\tloss: 1.164\tscore: 0.368\tagreement_ratio: 0.748\n",
      "INFO:root:epoch 3:\tloss: 1.144\tscore: 0.342\tagreement_ratio: 0.781\n",
      "INFO:root:epoch 4:\tloss: 1.132\tscore: 0.334\tagreement_ratio: 0.808\n",
      "INFO:root:epoch 5:\tloss: 1.128\tscore: 0.332\tagreement_ratio: 0.819\n",
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25694, 300) matrix from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_wostw_tuned.bin\n",
      "INFO:root:ISWD iteration: 0\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.260: 100% 856/856 [00:47<00:00, 18.20it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.221: 100% 856/856 [00:48<00:00, 17.51it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.220: 100% 856/856 [00:46<00:00, 18.50it/s]\n",
      "INFO:root:inner epoch: 3\n",
      "avg loss: 1.219: 100% 856/856 [00:47<00:00, 17.92it/s]\n",
      "[1.2601006762516276, 1.2214774538493045, 1.2198104737500581, 1.2193173621302453]\n",
      "100% 856/856 [00:46<00:00, 18.55it/s]\n",
      "64.89% (66.89% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4439940260294431\tmicro f1 score from student: 0.3400896095583529\n",
      "INFO:root:ISWD iteration: 1\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.188: 100% 856/856 [00:46<00:00, 18.25it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.186: 100% 856/856 [00:46<00:00, 18.47it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.186: 100% 856/856 [00:47<00:00, 17.99it/s]\n",
      "[1.1877712676667165, 1.1857028442182551, 1.1856805301906768]\n",
      "100% 856/856 [00:46<00:00, 18.58it/s]\n",
      "71.62% (73.40% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.42223170471516963\tmicro f1 score from student: 0.36633240879027096\n",
      "INFO:root:ISWD iteration: 2\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.164: 100% 856/856 [00:48<00:00, 17.82it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.163: 100% 856/856 [00:46<00:00, 18.47it/s]\n",
      "[1.1637571623252931, 1.163368395608023]\n",
      "100% 856/856 [00:45<00:00, 18.97it/s]\n",
      "74.40% (76.96% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.4068700661403883\tmicro f1 score from student: 0.35097077021548967\n",
      "INFO:root:ISWD iteration: 3\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.149: 100% 856/856 [00:47<00:00, 17.98it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.148: 100% 856/856 [00:48<00:00, 17.71it/s]\n",
      "INFO:root:inner epoch: 2\n",
      "avg loss: 1.148: 100% 856/856 [00:45<00:00, 18.65it/s]\n",
      "[1.1488911889093083, 1.1476046269776943, 1.147782166619028]\n",
      "100% 856/856 [00:48<00:00, 17.63it/s]\n",
      "78.54% (80.42% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.3821207595476851\tmicro f1 score from student: 0.33902282910177084\n",
      "INFO:root:ISWD iteration: 4\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.135: 100% 856/856 [00:46<00:00, 18.40it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.134: 100% 856/856 [00:46<00:00, 18.49it/s]\n",
      "[1.1346507878608514, 1.1340858816543473]\n",
      "100% 856/856 [00:46<00:00, 18.47it/s]\n",
      "80.48% (80.55% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.37806699381267334\tmicro f1 score from student: 0.331768721997013\n",
      "INFO:root:ISWD iteration: 5\n",
      "INFO:root:inner epoch: 0\n",
      "avg loss: 1.128: 100% 856/856 [00:47<00:00, 18.02it/s]\n",
      "INFO:root:inner epoch: 1\n",
      "avg loss: 1.127: 100% 856/856 [00:47<00:00, 18.10it/s]\n",
      "[1.1281426244493677, 1.1274849283813595]\n",
      "100% 856/856 [00:46<00:00, 18.51it/s]\n",
      "80.53% (82.22% after updating z) of samples have same result from student and teacher.\n",
      "testing result: micro f1 score from teacher: 0.38276082782163423\tmicro f1 score from student: 0.3319820780883294\n",
      "INFO:root:epoch 0:\tloss: 1.230\tscore: 0.340\tagreement_ratio: 0.649\n",
      "INFO:root:epoch 1:\tloss: 1.186\tscore: 0.366\tagreement_ratio: 0.716\n",
      "INFO:root:epoch 2:\tloss: 1.164\tscore: 0.351\tagreement_ratio: 0.744\n",
      "INFO:root:epoch 3:\tloss: 1.148\tscore: 0.339\tagreement_ratio: 0.785\n",
      "INFO:root:epoch 4:\tloss: 1.134\tscore: 0.332\tagreement_ratio: 0.805\n",
      "INFO:root:epoch 5:\tloss: 1.128\tscore: 0.332\tagreement_ratio: 0.805\n"
     ]
    }
   ],
   "source": [
    "! python parser.py --domain organic --experiment_mode multi-times --lr 0.005 --batch_size 512 --inner_iter 5 --epochs 4 --pretrained word2vec --wv_path ../wv/w2v_corpus_wotf1_wostw_tuned.bin --wv_mode tuned \\\n",
    "            --num_aspect 6 --dropout 0.4 --weight_decay 0.01 --data_dir ../processed/ --output_dir ../experiments/ --general_asp 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMFZWgoAqOPy"
   },
   "source": [
    "# Teacher Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHv_Ty5wq4cV",
    "outputId": "a4e90ee6-990a-47ff-d1e5-387d49751370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/group-1.3/LeverageJustAFewKeywords\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/group-1.3/LeverageJustAFewKeywords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlqPoxiFtAHC"
   },
   "outputs": [],
   "source": [
    "!pip install mittens transformers\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EvdOvr2s7Xt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from train import Trainer\n",
    "from utils import *\n",
    "from config import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlLko8mapQTZ",
    "outputId": "44c49433-7ddb-4dbb-cd02-05815d5cdbb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading dataset...\n",
      "INFO:root:[organic] dataset from following files: ../processed/organic_train.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_train_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] dataset_size: 438241\n",
      "INFO:root:[organic] number of aspects: 6\n",
      "INFO:root:[organic] number of unique seed words: 168\n",
      "INFO:root:[organic] test dataset from following files: ../processed/annotated_test_coarse.json, ../processed/organic_vocab_w2v.txt, ../processed/organic_test_supplement_w2v.pkl, ../processed/seedwords_30_coarse.txt\n",
      "INFO:root:[organic] test dataset size: 4687\n",
      "INFO:root:loading model...\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../wv/w2v_corpus_wotf1_tuned.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (25840, 300) matrix from ../wv/w2v_corpus_wotf1_tuned.bin\n",
      "INFO:root:[organic] load pre-defined word vectors from ../wv/w2v_corpus_wotf1_tuned.bin\n"
     ]
    }
   ],
   "source": [
    "hparams['domain'] = 'organic'\n",
    "hparams['data_dir'] = '../processed'\n",
    "aspect_name = read_aspect_name('../processed/organic_aspect_name_coarse.txt')\n",
    "hparams['general_asp'] = aspect_name.index('general')\n",
    "hparams['student']['num_aspect'] = len(aspect_name)\n",
    "hparams['student']['wv_path'] = '../wv/w2v_corpus_wotf1_tuned.bin'\n",
    "trainer = Trainer(hparams, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNTBmXppuYt-"
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "result = []\n",
    "ground = []\n",
    "for batch in trainer.test_loader:\n",
    "    idx, bow, labels, actual_len = batch\n",
    "    bow = bow.cuda()\n",
    "    labels = labels.cuda()\n",
    "    trainer.z = trainer.reset_z()   # no weight information\n",
    "    with torch.no_grad():\n",
    "        logits = trainer.teacher(bow, trainer.z)\n",
    "    result.append(logits.max(-1)[1].cpu())\n",
    "    ground.append(labels.max(-1)[1].cpu())\n",
    "result = torch.cat(result, dim=0)\n",
    "ground = torch.cat(ground, dim=0)\n",
    "score = f1_score(y_true=ground.numpy(), y_pred=result.numpy(), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sN30vJM4yZuy",
    "outputId": "5044ac67-f7e0-4d77-b31b-64d49b7c135a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45743545978237676"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK4i8n7G5hPR",
    "outputId": "59e64685-be6c-45d0-f113-4dfef753fc78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 168])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.z.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "organic_experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
